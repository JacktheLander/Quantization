### Temp = 0.1
Complete this poem: Do not go gentle into that good night, Old age should burn and rave at close of day; Rage, rage against the dying of the light.
[{'generated_text': 'Complete this poem: Do not go gentle into that good night, Old age should burn and rave at close of day; Rage, rage against the dying of the light.\nThe light of the moon, the light of the sun, the light of the stars, the light of the moon and the stars, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun and the moon, the light of the sun'}]
Model before:

 LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(32000, 2048)
    (layers): ModuleList(
      (0-21): 22 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
          (k_proj): Linear(in_features=2048, out_features=256, bias=False)
          (v_proj): Linear(in_features=2048, out_features=256, bias=False)
          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)
          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)
          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
      )
    )
    (norm): LlamaRMSNorm((2048,), eps=1e-05)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)
)
Complete this poem: Do not go gentle into that good night, Old age should burn and rave at close of day; Rage, rage against the dying of the light.
The light of the moon, the light of the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light of the moon and the sun, the light
Model after:

 LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(32000, 2048)
    (layers): ModuleList(
      (0-21): 22 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): W8A16LinearLayer()
          (k_proj): W8A16LinearLayer()
          (v_proj): W8A16LinearLayer()
          (o_proj): W8A16LinearLayer()
        )
        (mlp): LlamaMLP(
          (gate_proj): W8A16LinearLayer()
          (up_proj): W8A16LinearLayer()
          (down_proj): W8A16LinearLayer()
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
      )
    )
    (norm): LlamaRMSNorm((2048,), eps=1e-05)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)
)
